---
title: "regresion lineal"
author: "cristina malia"
date: "2023-03-27"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

ejercicio 1 

```{r include=FALSE}
install.packages("MASS", repos = "http://cran.us.r-project.org")
library(MASS)
install.packages("caret", repos = "http://cran.us.r-project.org")
install.packages("stats", repos = "http://cran.us.r-project.org")
install.packages("olsrr", repos = "http://cran.us.r-project.org")
install.packages("kable", repos = "http://cran.us.r-project.org")
install.packages("kableExtra", repos = "http://cran.us.r-project.org")
install.packages("knit", repos = "http://cran.us.r-project.org")
install.packages("rmarkdown", repos = "http://cran.us.r-project.org")
```
ejercicio 2

```{r}
y_cuentas = c(110,2,6,98,40,94,31,5,8,10)
x_distancia = c(1.1,100.2,90.3,5.4,57.5,6.6,34.7,65.8,57.9,86.1)

```

Ejercicio 3

```{r}
plot(x_distancia, y_cuentas)
```
```{r}
cor.test(x_distancia, y_cuentas)
```
Ejercicio 4
```{r}
hist(x_distancia, breaks = 10, main = "Histograma de x_distancia", xlab = "Distancia")
shapiro.test(x_distancia)

```
Ejercicio 5

```{r}
xy <- x_distancia * y_cuentas

```
Ejercicio 6

```{r}
x_cuadrado <- x_distancia^2

```

Ejercicio 7

```{r}
tabla_datos <- data.frame(y_cuentas, x_distancia, xy, x_cuadrado)

```
Ejercicio 8
```{r}
library(kableExtra)
kbl(tabla_datos)
```
Ejercicio 9

```{r}
colSums(tabla_datos)

```
Ejercicio 10

sumamos las 4 columnas

```{r}
sumatorio_columnas = colSums(tabla_datos[, 1:4])
sumatorio_columnas
```

Añadimos esos valores como 1 fila al data frame
Creamos primero un data frame con los nuevos valores
```{r}
totales_sumatorio = data.frame(x_distancia = c(505.60), y_cuentas =c(404.00), xy = c(7041.70), x_cuadrado =c(37873.66))
```
Para luego añadirselo como fila al data frame sumatorio_columnas_df
```{r}
sumatorio_columnas_df =rbind(tabla_datos, totales_sumatorio)

kbl(sumatorio_columnas_df)%>%
kable_minimal() %>%
row_spec(nrow(sumario_columna_df), bold =TRUE, color = "black", background = "white")
```

Ejercicio 11

```{r}
# Sumamos x e y
404*505.6
#EntreNumCasos
204262.4/10
#SumatorioXY-Anterior
7041.7-20426.24
#X2
505.6^2
#EntreNumCasos
255631.4/10
#SumatorioX2-Anterior
37873.66-25563.14
#Primero/Segundo
-13384.54/12310.52
#SumatorioX/NumeroCasos+NumeroAnterior*SumatorioY/NumeroCasos
404/10+1.087244*505.6/10
```
Ejercicio 12

```{r}
# Cargar paquetes
library(ggplot2)

# Ajustar modelo de regresión lineal
modelo <- lm(y ~ x, data = datos)

# Crear gráfico de dispersión con recta de regresión
ggplot(data = datos, aes(x = x, y = y)) +
  geom_point() + # Agregar nube de puntos
  geom_smooth(method = "lm", se = FALSE, color = "red") + # Agregar recta de regresión
  labs(title = "Gráfico de dispersión con recta de regresión",
       x = "Variable X", y = "Variable Y") + # Editar título y nombres de ejes
  geom_text(aes(x= max(datos$x), y= max(datos$y), label= paste("y =", round(coef(modelo)[2],2), "x +", round(coef(modelo)[1],2))), hjust= 1, vjust=1) # Agregar la ecuación de la recta de regresión

```

Ejercicio 13

```{r}
# Calcular los residuos
residuos <- resid(modelo)

# Calcular los residuos estandarizados
residuos_estandarizados <- rstandard(modelo)

# Calcular los residuos estudentizados
residuos_estudentizados <- rstudent(modelo)

```

Ejercio 14

```{r}
# Crear una matriz con la observación de interés
nueva_obs <- data.frame(distancia_km = 6.6)

# Calcular el pronóstico o estimación del modelo para la nueva observación
pronostico <- predict(modelo, newdata = nueva_obs)

# Mostrar el resultado
pronostico

```






Ejercicio 15
```{r}
library(dplyr)
train <- data %>% dplyr: : sample_frac(.8)
test <- dplyr:: anti_join((data, train)
```

Ejercicio 16

```{r}
library (stats)
modelo1<- ~ x_distancia, entrenamiento)
summary(modelo1)
```

Ejercicio 17

```{r}
#Prediciendo el conjunto de validación
prediccion_validacion <- predict(modelo_entrenamiento, newdata = data.frame(x_distancia_validacion))
prediccion_validacion

#Los asteriscos inmediatamente a la derecha de los valores arrojados tras ajustar el modelo, son usados para indicar los intervalos de confianza. Estos intervalos de confianza, a su vez, nos muestran la incertidumbre que hay en los valores estimados por el modelo.
```

Ejercicio 18
```{r}

Los grados de libertad del modelo se calculan restando el número total de parámetros estimados en el modelo del número total de observaciones. En otras palabras, los grados de libertad son el número de observaciones menos el número de parámetros estimados. Por ejemplo, si el modelo tiene 5 parámetros estimados y hay 10 observaciones, entonces los grados de libertad del modelo serán 5.
```

Ejercicio 19
```{r}
# Ajustar modelo de regresión lineal simple
modelo <- lm(y ~ x, data = datos)

# Obtener resumen del modelo
resumen_modelo <- summary(modelo)

# Total de varianza explicada
varianza_explicada <- sum(resumen_modelo$fstatistic[2])

# Total de varianza no explicada
varianza_no_explicada <- sum(resumen_modelo$fstatistic[3])


```


























